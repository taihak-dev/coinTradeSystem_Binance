import os
import sqlite3
import time
import logging
from datetime import datetime, timedelta, timezone
import pandas as pd
from binance.um_futures import UMFutures
from binance.error import ClientError

# --- ê¸°ë³¸ ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- ì‚¬ìš©ì ì„¤ì • ---
MARKET_TO_COLLECT = "DOGEUSDT"
START_DATE_STR = "2025-11-22 00:00:00"
END_DATE_STR = "2025-12-04 23:59:59"

# --- DB ì„¤ì • ---
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(PROJECT_ROOT, "db", "candle_db.sqlite")


# --- DB ê´€ë ¨ í•¨ìˆ˜ ---
def ensure_table_exists():
    """DBì™€ í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±"""
    db_dir = os.path.dirname(DB_PATH)
    if not os.path.exists(db_dir):
        os.makedirs(db_dir)
        logging.info(f"ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬({db_dir})ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
    with sqlite3.connect(DB_PATH) as conn:
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS minute_candles (
                market TEXT, timestamp TEXT, open REAL, high REAL, low REAL, close REAL, volume REAL,
                PRIMARY KEY (market, timestamp)
            )
        """)
        logging.info("âœ… 'minute_candles' í…Œì´ë¸” ì¤€ë¹„ ì™„ë£Œ.")


def save_candles_to_db(candles_df: pd.DataFrame):
    """ë°ì´í„°í”„ë ˆì„ì„ DBì— ì €ì¥"""
    if candles_df.empty:
        return 0
    with sqlite3.connect(DB_PATH) as conn:
        cursor = conn.cursor()
        insert_count = 0
        for _, row in candles_df.iterrows():
            try:
                cursor.execute("""
                    INSERT INTO minute_candles (market, timestamp, open, high, low, close, volume)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, tuple(row))
                insert_count += 1
            except sqlite3.IntegrityError:
                continue
        conn.commit()
        logging.info(f"ğŸ’¾ ì‹ ê·œ ìº”ë“¤ {insert_count}ê°œ ì €ì¥ ì™„ë£Œ.")
        return insert_count


def get_last_timestamp_from_db(market: str) -> datetime | None:
    """DBì—ì„œ íŠ¹ì • ë§ˆì¼“ì˜ ê°€ì¥ ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¡°íšŒ"""
    if not os.path.exists(DB_PATH):
        return None
    with sqlite3.connect(DB_PATH) as conn:
        cursor = conn.cursor()
        try:
            cursor.execute("SELECT MAX(timestamp) FROM minute_candles WHERE market = ?", (market,))
            result = cursor.fetchone()[0]
            if result:
                # ì €ì¥ëœ timestamp ë¬¸ìì—´ì„ UTC datetime ê°ì²´ë¡œ ë³€í™˜
                return datetime.strptime(result, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
        except Exception:
            return None
    return None


# --- ë©”ì¸ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def collect_all_candles():
    """ì„¤ì •ëœ ê¸°ê°„ ë™ì•ˆì˜ ëª¨ë“  1ë¶„ë´‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘"""
    ensure_table_exists()

    user_start_dt_utc = datetime.strptime(START_DATE_STR, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
    end_dt_utc = datetime.strptime(END_DATE_STR, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)

    # --- ğŸ‘‡ğŸ‘‡ğŸ‘‡ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ ğŸ‘‡ğŸ‘‡ğŸ‘‡ ---
    # DBì˜ ë§ˆì§€ë§‰ ì‹œê°„ì„ í™•ì¸í•˜ëŠ” ë¡œì§ì„ ì‚­ì œí•˜ê³ ,
    # í•­ìƒ ì‚¬ìš©ìê°€ ì„¤ì •í•œ ì‹œì‘ ì‹œê°„(user_start_dt_utc)ì„ ì‚¬ìš©í•˜ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.
    start_dt_utc = user_start_dt_utc
    logging.info(f"â„¹ï¸ ì‚¬ìš©ìê°€ ì„¤ì •í•œ ì‹œì‘ ì‹œê°„({start_dt_utc})ë¶€í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # (ì„ íƒ ì‚¬í•­) DB ë§ˆì§€ë§‰ ì‹œê°„ì€ ì°¸ê³ ìš©ìœ¼ë¡œ ë¡œê·¸ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    last_saved_dt = get_last_timestamp_from_db(MARKET_TO_COLLECT)
    if last_saved_dt:
        logging.info(f"ğŸ” (ì°¸ê³ ) DBì— ì´ë¯¸ ì €ì¥ëœ ë§ˆì§€ë§‰ ë°ì´í„° ì‹œì : {last_saved_dt}")
    # --- ğŸ‘†ğŸ‘†ğŸ‘† ìˆ˜ì • ì™„ë£Œ --- ğŸ‘†ğŸ‘†ğŸ‘†

    if start_dt_utc >= end_dt_utc:
        logging.info("âœ… ì´ë¯¸ ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤. ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    logging.info(f"--- ğŸ•¯ï¸ {MARKET_TO_COLLECT} ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (UTC ê¸°ì¤€) ---")
    logging.info(f"ê¸°ê°„: {start_dt_utc} ~ {end_dt_utc}")

    try:
        client = UMFutures()
        client.session.timeout = 15
        logging.info("âœ… ë°”ì´ë‚¸ìŠ¤ ê³µìš© í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ!")
    except Exception as e:
        logging.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return

    current_dt = start_dt_utc
    total_saved_count = 0

    while current_dt < end_dt_utc:
        start_time_ms = int(current_dt.timestamp() * 1000)

        logging.info(f"ğŸ”„ {current_dt.strftime('%Y-%m-%d %H:%M:%S')}ë¶€í„° 1000ê°œ ìº”ë“¤ ìš”ì²­...")

        try:
            klines = client.klines(
                symbol=MARKET_TO_COLLECT,
                interval='1m',
                startTime=start_time_ms,
                limit=1000
            )

            if not klines:
                logging.info("APIë¡œë¶€í„° ë” ì´ìƒ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ì¢…ë£Œ.")
                break

            df = pd.DataFrame(klines, columns=[
                'open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',
                'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume',
                'taker_buy_quote_asset_volume', 'ignore'
            ])

            df['market'] = MARKET_TO_COLLECT

            # --- ğŸ‘‡ğŸ‘‡ğŸ‘‡ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ ğŸ‘‡ğŸ‘‡ğŸ‘‡ ---
            # 1. 'ë‚ ì§œ ê°ì²´' ì»¬ëŸ¼ì„ ë¨¼ì € ë§Œë“­ë‹ˆë‹¤.
            df['dt_timestamp'] = pd.to_datetime(df['open_time'], unit='ms', utc=True)

            # 2. 'ë‚ ì§œ ê°ì²´'ë¡œ ì¦‰ì‹œ í•„í„°ë§í•©ë‹ˆë‹¤. (ê²½ê³ ê°€ ë°œìƒí•˜ë˜ ì´ì¤‘ ë³€í™˜ì„ ì œê±°)
            df_filtered = df[df['dt_timestamp'] <= end_dt_utc].copy()

            if df_filtered.empty:
                logging.info("ë‚¨ì€ ìº”ë“¤ì´ ëª¨ë‘ ìˆ˜ì§‘ ê¸°ê°„ ì´í›„ì˜ ë°ì´í„°ì´ë¯€ë¡œ ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            # 3. DBì— ì €ì¥í•  'í…ìŠ¤íŠ¸' ì»¬ëŸ¼ì„ *í•„í„°ë§ì´ ëë‚œ í›„ì—* ë§Œë“­ë‹ˆë‹¤.
            df_filtered['timestamp'] = df_filtered['dt_timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')

            # 4. ìµœì¢… ì €ì¥í•  ë°ì´í„°í”„ë ˆì„ì„ ì„ íƒí•©ë‹ˆë‹¤.
            df_to_save = df_filtered[['market', 'timestamp', 'open', 'high', 'low', 'close', 'volume']]
            # --- ğŸ‘†ğŸ‘†ğŸ‘† ìˆ˜ì • ì™„ë£Œ --- ğŸ‘†ğŸ‘†ğŸ‘†

            saved_count = save_candles_to_db(df_to_save)
            total_saved_count += saved_count

            # 'df' (í•„í„°ë§ ì „ ì›ë³¸)ì˜ ë§ˆì§€ë§‰ ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒ ë£¨í”„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
            last_open_time_ms = df.iloc[-1]['open_time']
            current_dt = datetime.fromtimestamp(last_open_time_ms / 1000, tz=timezone.utc) + timedelta(minutes=1)

            time.sleep(0.5)

        except ClientError as e:
            logging.error(f"API ì˜¤ë¥˜ ë°œìƒ (Code: {e.error_code}): {e.error_message}. 5ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(5)
        except Exception as e:
            logging.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}. 5ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(5)

    logging.info(f"--- âœ… ìˆ˜ì§‘ ì™„ë£Œ. ì´ {total_saved_count}ê°œì˜ ì‹ ê·œ ìº”ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ---")


if __name__ == "__main__":
    collect_all_candles()